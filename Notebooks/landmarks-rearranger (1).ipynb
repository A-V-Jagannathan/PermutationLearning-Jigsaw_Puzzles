{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff5ba52",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-10T14:42:23.082095Z",
     "iopub.status.busy": "2023-04-10T14:42:23.081661Z",
     "iopub.status.idle": "2023-04-10T14:42:32.069173Z",
     "shell.execute_reply": "2023-04-10T14:42:32.067861Z"
    },
    "papermill": {
     "duration": 8.996112,
     "end_time": "2023-04-10T14:42:32.072682",
     "exception": false,
     "start_time": "2023-04-10T14:42:23.076570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import log\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow import zeros_like,reduce_sum,divide,exp,expand_dims\n",
    "from tensorflow.keras.layers import Input, TimeDistributed,Flatten,Dense,Dropout,Reshape\n",
    "\n",
    "\n",
    "sys.path.append('/kaggle/input/mlware-preprocessed')\n",
    "from DataHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab01c731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T14:42:32.084383Z",
     "iopub.status.busy": "2023-04-10T14:42:32.083760Z",
     "iopub.status.idle": "2023-04-10T14:42:32.090278Z",
     "shell.execute_reply": "2023-04-10T14:42:32.089269Z"
    },
    "papermill": {
     "duration": 0.019152,
     "end_time": "2023-04-10T14:42:32.099196",
     "exception": false,
     "start_time": "2023-04-10T14:42:32.080044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of functions availabe to be used:\n",
      "\n",
      "\n",
      "1.load_images(path,valid_split):\n",
      "Takes in 2 parameters, returns 2 numpy arrays, corresponding to training and test set. \n",
      "    \n",
      "    This function is used to load the images as arrays for training and validation.\n",
      "    Format for loading images:\n",
      "        -> Under path, there must be N folders, each of the folders having the n different splitted pieces of the image\n",
      "        -> To generate the suitable format , use CreateDataset function(number 8 in Help) and cut->paste all the folders into a different directory.\n",
      "    Example usage:\n",
      "train,test=load_images(\"c:/images/puzzles\",0.2)\n",
      "    \n",
      "    \n",
      "2.generatePM(N,n,split):\n",
      "Produces a (nxn) permutation matrix representing the ground truth for an unshuffled image. \n",
      "    \n",
      "    N is the number of images for which permutation matrix has to be generated,\n",
      "    n is the total number of pieces(square board)\n",
      "    split is ratio between training and test set\n",
      "    Example usage:\n",
      "y_train,y_test=generatePM(train.shape[0]+test.shape[0], 36, 0.2)\n",
      "    \n",
      "    \n",
      "3.AugmentedData(x,y,number,augments_per_image=8):\n",
      "Takes in 3 parameters, x( the image matrix ), y( the ground truth permutation matrix)\n",
      "    returns 2 numpy arrays, corresponding to new_x,new_y , in which there are \"number\" ( a parameter) of data, each of them shuffled versions of the input imagess\n",
      "    \n",
      "    Due to nature of permutation learning you can generate anywhere from 10 to 100 times the initial data size without worrying about duplicates.\n",
      "    increase augments_per_image to improve differences between each image.\n",
      "    Example usage:\n",
      "    newx,newy=AugmentedData(x,y,10000,augments_per_image=15)\n",
      "    \n",
      "    \n",
      "4.loadAnImage(path,height,width):\n",
      "Takes in 2 parameters, returns a numpy array consisting N*M splitted image. \n",
      "    \n",
      "    Splits the input image into N*M images where each piece has Height of height and Width of width ( parameters).\n",
      "    Example usage:\n",
      "img=loadAnImage(\"c:/images/puzzles/imageNo1.jpg\",50,50)\n",
      "    \n",
      "    \n",
      "5.shuffleAnImage(arr,shuffles):\n",
      "Takes in 2 parameters, returns a numpy array. \n",
      "    \n",
      "    Shuffles the image pieces of input array for \"shuffles\" amount of times, and returns it.\n",
      "    Example usage:\n",
      "img=shuffleAnImag(arr,50)\n",
      "    \n",
      "    \n",
      "6.showImgarr(arr,height,width):\n",
      "Takes in the array and the final image's height and width as parameter, prints the image version of it. \n",
      "    \n",
      "    used to display the image. pass the output from shuffleAnImage or loadAnImage or any np array resembling it, along with desired\n",
      "    height and width of the final image.\n",
      "    Example usage:\n",
      "showImgarr(arr,300,300)\n",
      "    \n",
      "    \n",
      "7.createImage(shuffled,P):\n",
      "Takes in the shuffled image array and the predictions from the Model(A permutation matrix)\n",
      "    as parameters, returns the final image after reshuffling. \n",
      "    \n",
      "    To see the predicted image , follow the following:\n",
      "    Example usage:\n",
      "    predictions=model.predict(array)\n",
      "    img=showImgarr(shuffled,predictions)\n",
      "    showImgarr(img,height,width)\n",
      "    \n",
      "    \n",
      "8.CreateDataset(direc,height,width,extension=\".jpg\"):\n",
      "Takes in 4 parameters, directory under which the images are present, \n",
      "    height of each piece( piece is each puzzle piece not the image) , width of each piece and extension of each image.\n",
      "    \n",
      "    Generates n folders(n is the number of images), each having the splitted pieces inside it. Cut and paste every folder in a seperate directory to load them\n",
      "    using load_images function\n",
      "    Example usage:\n",
      "    CreateDataset(\"C:/images/\",50,50)\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "helpMe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04fbc20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T14:42:32.106143Z",
     "iopub.status.busy": "2023-04-10T14:42:32.105865Z",
     "iopub.status.idle": "2023-04-10T14:50:06.489348Z",
     "shell.execute_reply": "2023-04-10T14:50:06.488192Z"
    },
    "papermill": {
     "duration": 454.389745,
     "end_time": "2023-04-10T14:50:06.492056",
     "exception": false,
     "start_time": "2023-04-10T14:42:32.102311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train,x_test = load_images(\"/kaggle/input/mlware-preprocessed/Landmarks_train\",valid_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6171225f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T14:50:06.499925Z",
     "iopub.status.busy": "2023-04-10T14:50:06.499004Z",
     "iopub.status.idle": "2023-04-10T14:50:08.143749Z",
     "shell.execute_reply": "2023-04-10T14:50:08.142701Z"
    },
    "papermill": {
     "duration": 1.65087,
     "end_time": "2023-04-10T14:50:08.146258",
     "exception": false,
     "start_time": "2023-04-10T14:50:06.495388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y=PermutationMatrix(\"/kaggle/input/mlware-preprocessed/Preprocessed_landmarks.csv\")\n",
    "y_train,y_test=y[:ceil(y.shape[0]*0.8)],y[ceil(y.shape[0]*0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9450c21b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T14:50:08.153469Z",
     "iopub.status.busy": "2023-04-10T14:50:08.152719Z",
     "iopub.status.idle": "2023-04-10T15:43:46.887349Z",
     "shell.execute_reply": "2023-04-10T15:43:46.886195Z"
    },
    "papermill": {
     "duration": 3218.740921,
     "end_time": "2023-04-10T15:43:46.890032",
     "exception": false,
     "start_time": "2023-04-10T14:50:08.149111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "newx_train,newy_train=AugmentedData(x_train,y_train,6000,augments_per_image=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2190bae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T15:43:46.897590Z",
     "iopub.status.busy": "2023-04-10T15:43:46.897284Z",
     "iopub.status.idle": "2023-04-10T15:44:04.668384Z",
     "shell.execute_reply": "2023-04-10T15:44:04.667333Z"
    },
    "papermill": {
     "duration": 17.777727,
     "end_time": "2023-04-10T15:44:04.670863",
     "exception": false,
     "start_time": "2023-04-10T15:43:46.893136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "newx_test,newy_test=AugmentedData(x_test,y_test,400,augments_per_image=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4cdd67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T15:44:04.677952Z",
     "iopub.status.busy": "2023-04-10T15:44:04.677628Z",
     "iopub.status.idle": "2023-04-10T15:44:13.741750Z",
     "shell.execute_reply": "2023-04-10T15:44:13.740749Z"
    },
    "papermill": {
     "duration": 9.070388,
     "end_time": "2023-04-10T15:44:13.744161",
     "exception": false,
     "start_time": "2023-04-10T15:44:04.673773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "31790344/31790344 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "class SinkhornLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon=0.1, n_iters=10):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "    def sinkhorn(self, x):\n",
    "        # Sinkhorn iterations\n",
    "        self.u = zeros_like(x[:, 0])\n",
    "        self.v = zeros_like(x[0])\n",
    "        for i in range(self.n_iters):\n",
    "            self.u = -self.epsilon * (log(reduce_sum(exp(divide(x - expand_dims(self.v, axis=1), self.epsilon)), axis=2))) + self.u\n",
    "            self.v = -self.epsilon * (log(reduce_sum(exp(divide(x - expand_dims(self.u, axis=2), self.epsilon)), axis=1))) + self.v\n",
    "\n",
    "        # Compute the sinkhorn matrix\n",
    "        sinkhorn_matrix = exp(divide(x - expand_dims(self.u, axis=2) - expand_dims(self.v, axis=1), self.epsilon))\n",
    "\n",
    "        return sinkhorn_matrix\n",
    "def create_siamese_network():\n",
    "    # Define the input layer\n",
    "    inputs = Input(shape=(36, 50, 50, 3))\n",
    "    \n",
    "    # Define the shared layers of the Siamese network using EffiecientNet architecture\n",
    "    shared_layers = EfficientNetB2(\n",
    "        input_shape=(50, 50, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    shared_layers.trainable = False\n",
    "\n",
    "    # Apply the shared layers to each input image\n",
    "    x = TimeDistributed(shared_layers)(inputs)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Add a fully connected layer to output a vector of length 1296\n",
    "    fc1 = Dense(1024, activation='relu')(x)\n",
    "    fc1 = Dropout(0.2)(fc1)  # Add dropout\n",
    "    fc2 = Dense(512, activation='relu')(fc1)\n",
    "    fc2 = Dropout(0.2)(fc2)  # Add dropout\n",
    "    output = Dense(1296, activation='softmax')(fc2)\n",
    "    \n",
    "    # Reshape output to a 36x36 one-hot encoded matrix\n",
    "    reshaped_output = Reshape((36, 36))(output)\n",
    "    sinkhorn_output = SinkhornLayer()(reshaped_output)\n",
    "    \n",
    "    # Define the Siamese model with 36 inputs and one output\n",
    "    model = Model(inputs=inputs, outputs= sinkhorn_output)\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the Siamese network with input shape (50, 50, 3) and outputting a 36x36 one-hot encoded matrix\n",
    "siamese_network = create_siamese_network()\n",
    "siamese_network.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.00001),metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f184476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T15:44:13.752036Z",
     "iopub.status.busy": "2023-04-10T15:44:13.751742Z",
     "iopub.status.idle": "2023-04-11T01:05:51.816426Z",
     "shell.execute_reply": "2023-04-11T01:05:51.815288Z"
    },
    "papermill": {
     "duration": 33698.071203,
     "end_time": "2023-04-11T01:05:51.818862",
     "exception": false,
     "start_time": "2023-04-10T15:44:13.747659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 15:44:29.101472: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/time_distributed/efficientnetb2/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 100s 305ms/step - loss: 3.5897 - accuracy: 0.0283 - val_loss: 3.5840 - val_accuracy: 0.0281\n",
      "Epoch 2/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 3.5832 - accuracy: 0.0297 - val_loss: 3.5845 - val_accuracy: 0.0284\n",
      "Epoch 3/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 3.5816 - accuracy: 0.0317 - val_loss: 3.5851 - val_accuracy: 0.0269\n",
      "Epoch 4/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 3.5788 - accuracy: 0.0335 - val_loss: 3.5865 - val_accuracy: 0.0282\n",
      "Epoch 5/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 3.5732 - accuracy: 0.0376 - val_loss: 3.5879 - val_accuracy: 0.0274\n",
      "Epoch 6/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 3.5639 - accuracy: 0.0422 - val_loss: 3.5907 - val_accuracy: 0.0267\n",
      "Epoch 7/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.5506 - accuracy: 0.0483 - val_loss: 3.5965 - val_accuracy: 0.0272\n",
      "Epoch 8/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 3.5315 - accuracy: 0.0552 - val_loss: 3.5971 - val_accuracy: 0.0268\n",
      "Epoch 9/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 3.5077 - accuracy: 0.0629 - val_loss: 3.6032 - val_accuracy: 0.0300\n",
      "Epoch 10/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.4800 - accuracy: 0.0715 - val_loss: 3.6090 - val_accuracy: 0.0274\n",
      "Epoch 11/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 3.4464 - accuracy: 0.0823 - val_loss: 3.6180 - val_accuracy: 0.0269\n",
      "Epoch 12/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.4098 - accuracy: 0.0927 - val_loss: 3.6228 - val_accuracy: 0.0276\n",
      "Epoch 13/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 3.3680 - accuracy: 0.1044 - val_loss: 3.6298 - val_accuracy: 0.0288\n",
      "Epoch 14/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.3270 - accuracy: 0.1162 - val_loss: 3.6372 - val_accuracy: 0.0278\n",
      "Epoch 15/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 3.2840 - accuracy: 0.1275 - val_loss: 3.6425 - val_accuracy: 0.0288\n",
      "Epoch 16/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.2417 - accuracy: 0.1391 - val_loss: 3.6537 - val_accuracy: 0.0276\n",
      "Epoch 17/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.1985 - accuracy: 0.1510 - val_loss: 3.6579 - val_accuracy: 0.0274\n",
      "Epoch 18/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.1550 - accuracy: 0.1625 - val_loss: 3.6668 - val_accuracy: 0.0280\n",
      "Epoch 19/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.1149 - accuracy: 0.1723 - val_loss: 3.6744 - val_accuracy: 0.0272\n",
      "Epoch 20/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 3.0723 - accuracy: 0.1847 - val_loss: 3.6787 - val_accuracy: 0.0272\n",
      "Epoch 21/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 3.0341 - accuracy: 0.1934 - val_loss: 3.6851 - val_accuracy: 0.0281\n",
      "Epoch 22/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.9919 - accuracy: 0.2042 - val_loss: 3.6959 - val_accuracy: 0.0270\n",
      "Epoch 23/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.9541 - accuracy: 0.2149 - val_loss: 3.6994 - val_accuracy: 0.0275\n",
      "Epoch 24/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.9159 - accuracy: 0.2246 - val_loss: 3.7043 - val_accuracy: 0.0273\n",
      "Epoch 25/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.8801 - accuracy: 0.2328 - val_loss: 3.7117 - val_accuracy: 0.0279\n",
      "Epoch 26/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.8419 - accuracy: 0.2428 - val_loss: 3.7189 - val_accuracy: 0.0289\n",
      "Epoch 27/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.8065 - accuracy: 0.2525 - val_loss: 3.7257 - val_accuracy: 0.0279\n",
      "Epoch 28/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.7751 - accuracy: 0.2592 - val_loss: 3.7305 - val_accuracy: 0.0280\n",
      "Epoch 29/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 2.7412 - accuracy: 0.2692 - val_loss: 3.7373 - val_accuracy: 0.0274\n",
      "Epoch 30/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.7082 - accuracy: 0.2766 - val_loss: 3.7424 - val_accuracy: 0.0269\n",
      "Epoch 31/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.6766 - accuracy: 0.2855 - val_loss: 3.7495 - val_accuracy: 0.0279\n",
      "Epoch 32/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.6483 - accuracy: 0.2920 - val_loss: 3.7545 - val_accuracy: 0.0278\n",
      "Epoch 33/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.6164 - accuracy: 0.3004 - val_loss: 3.7601 - val_accuracy: 0.0270\n",
      "Epoch 34/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.5855 - accuracy: 0.3068 - val_loss: 3.7670 - val_accuracy: 0.0279\n",
      "Epoch 35/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 2.5592 - accuracy: 0.3141 - val_loss: 3.7710 - val_accuracy: 0.0284\n",
      "Epoch 36/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.5309 - accuracy: 0.3213 - val_loss: 3.7804 - val_accuracy: 0.0268\n",
      "Epoch 37/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.5042 - accuracy: 0.3277 - val_loss: 3.7842 - val_accuracy: 0.0272\n",
      "Epoch 38/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.4778 - accuracy: 0.3335 - val_loss: 3.7888 - val_accuracy: 0.0264\n",
      "Epoch 39/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 2.4502 - accuracy: 0.3395 - val_loss: 3.7935 - val_accuracy: 0.0277\n",
      "Epoch 40/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.4261 - accuracy: 0.3450 - val_loss: 3.8001 - val_accuracy: 0.0268\n",
      "Epoch 41/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.4037 - accuracy: 0.3523 - val_loss: 3.8092 - val_accuracy: 0.0267\n",
      "Epoch 42/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.3768 - accuracy: 0.3582 - val_loss: 3.8126 - val_accuracy: 0.0259\n",
      "Epoch 43/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.3558 - accuracy: 0.3629 - val_loss: 3.8156 - val_accuracy: 0.0259\n",
      "Epoch 44/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.3285 - accuracy: 0.3706 - val_loss: 3.8193 - val_accuracy: 0.0270\n",
      "Epoch 45/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.3056 - accuracy: 0.3753 - val_loss: 3.8334 - val_accuracy: 0.0266\n",
      "Epoch 46/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.2878 - accuracy: 0.3802 - val_loss: 3.8324 - val_accuracy: 0.0264\n",
      "Epoch 47/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.2626 - accuracy: 0.3866 - val_loss: 3.8413 - val_accuracy: 0.0274\n",
      "Epoch 48/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.2405 - accuracy: 0.3913 - val_loss: 3.8407 - val_accuracy: 0.0276\n",
      "Epoch 49/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.2214 - accuracy: 0.3945 - val_loss: 3.8474 - val_accuracy: 0.0265\n",
      "Epoch 50/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.1988 - accuracy: 0.4013 - val_loss: 3.8539 - val_accuracy: 0.0270\n",
      "Epoch 51/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.1805 - accuracy: 0.4057 - val_loss: 3.8598 - val_accuracy: 0.0273\n",
      "Epoch 52/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.1596 - accuracy: 0.4099 - val_loss: 3.8687 - val_accuracy: 0.0270\n",
      "Epoch 53/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.1398 - accuracy: 0.4158 - val_loss: 3.8684 - val_accuracy: 0.0268\n",
      "Epoch 54/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.1217 - accuracy: 0.4199 - val_loss: 3.8707 - val_accuracy: 0.0269\n",
      "Epoch 55/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.0997 - accuracy: 0.4240 - val_loss: 3.8810 - val_accuracy: 0.0272\n",
      "Epoch 56/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.0842 - accuracy: 0.4284 - val_loss: 3.8841 - val_accuracy: 0.0270\n",
      "Epoch 57/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.0659 - accuracy: 0.4324 - val_loss: 3.8846 - val_accuracy: 0.0274\n",
      "Epoch 58/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.0493 - accuracy: 0.4367 - val_loss: 3.8944 - val_accuracy: 0.0267\n",
      "Epoch 59/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 2.0288 - accuracy: 0.4413 - val_loss: 3.9009 - val_accuracy: 0.0272\n",
      "Epoch 60/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 2.0115 - accuracy: 0.4449 - val_loss: 3.9055 - val_accuracy: 0.0259\n",
      "Epoch 61/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 1.9946 - accuracy: 0.4500 - val_loss: 3.9100 - val_accuracy: 0.0261\n",
      "Epoch 62/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 1.9785 - accuracy: 0.4536 - val_loss: 3.9229 - val_accuracy: 0.0268\n",
      "Epoch 63/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 1.9573 - accuracy: 0.4594 - val_loss: 3.9231 - val_accuracy: 0.0275\n",
      "Epoch 64/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.9473 - accuracy: 0.4614 - val_loss: 3.9302 - val_accuracy: 0.0264\n",
      "Epoch 65/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.9303 - accuracy: 0.4666 - val_loss: 3.9319 - val_accuracy: 0.0274\n",
      "Epoch 66/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.9132 - accuracy: 0.4688 - val_loss: 3.9375 - val_accuracy: 0.0271\n",
      "Epoch 67/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.8992 - accuracy: 0.4735 - val_loss: 3.9479 - val_accuracy: 0.0281\n",
      "Epoch 68/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.8872 - accuracy: 0.4753 - val_loss: 3.9508 - val_accuracy: 0.0266\n",
      "Epoch 69/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.8702 - accuracy: 0.4793 - val_loss: 3.9494 - val_accuracy: 0.0264\n",
      "Epoch 70/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.8558 - accuracy: 0.4821 - val_loss: 3.9567 - val_accuracy: 0.0265\n",
      "Epoch 71/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.8410 - accuracy: 0.4865 - val_loss: 3.9590 - val_accuracy: 0.0266\n",
      "Epoch 72/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.8253 - accuracy: 0.4916 - val_loss: 3.9700 - val_accuracy: 0.0264\n",
      "Epoch 73/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 1.8094 - accuracy: 0.4935 - val_loss: 3.9733 - val_accuracy: 0.0265\n",
      "Epoch 74/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7987 - accuracy: 0.4972 - val_loss: 3.9792 - val_accuracy: 0.0271\n",
      "Epoch 75/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7854 - accuracy: 0.4994 - val_loss: 3.9792 - val_accuracy: 0.0272\n",
      "Epoch 76/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7699 - accuracy: 0.5040 - val_loss: 3.9890 - val_accuracy: 0.0286\n",
      "Epoch 77/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7584 - accuracy: 0.5062 - val_loss: 3.9941 - val_accuracy: 0.0273\n",
      "Epoch 78/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7426 - accuracy: 0.5103 - val_loss: 3.9974 - val_accuracy: 0.0278\n",
      "Epoch 79/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7335 - accuracy: 0.5126 - val_loss: 4.0011 - val_accuracy: 0.0269\n",
      "Epoch 80/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.7219 - accuracy: 0.5152 - val_loss: 4.0056 - val_accuracy: 0.0274\n",
      "Epoch 81/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.7062 - accuracy: 0.5188 - val_loss: 4.0122 - val_accuracy: 0.0286\n",
      "Epoch 82/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6964 - accuracy: 0.5212 - val_loss: 4.0159 - val_accuracy: 0.0279\n",
      "Epoch 83/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6819 - accuracy: 0.5253 - val_loss: 4.0186 - val_accuracy: 0.0276\n",
      "Epoch 84/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6742 - accuracy: 0.5266 - val_loss: 4.0272 - val_accuracy: 0.0273\n",
      "Epoch 85/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6609 - accuracy: 0.5294 - val_loss: 4.0314 - val_accuracy: 0.0271\n",
      "Epoch 86/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 1.6455 - accuracy: 0.5343 - val_loss: 4.0356 - val_accuracy: 0.0278\n",
      "Epoch 87/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6349 - accuracy: 0.5352 - val_loss: 4.0424 - val_accuracy: 0.0277\n",
      "Epoch 88/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6249 - accuracy: 0.5384 - val_loss: 4.0465 - val_accuracy: 0.0277\n",
      "Epoch 89/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6160 - accuracy: 0.5402 - val_loss: 4.0529 - val_accuracy: 0.0279\n",
      "Epoch 90/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.6019 - accuracy: 0.5439 - val_loss: 4.0561 - val_accuracy: 0.0276\n",
      "Epoch 91/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5952 - accuracy: 0.5452 - val_loss: 4.0544 - val_accuracy: 0.0283\n",
      "Epoch 92/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5816 - accuracy: 0.5495 - val_loss: 4.0685 - val_accuracy: 0.0278\n",
      "Epoch 93/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5744 - accuracy: 0.5506 - val_loss: 4.0605 - val_accuracy: 0.0284\n",
      "Epoch 94/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5617 - accuracy: 0.5548 - val_loss: 4.0686 - val_accuracy: 0.0276\n",
      "Epoch 95/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5534 - accuracy: 0.5560 - val_loss: 4.0710 - val_accuracy: 0.0283\n",
      "Epoch 96/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5438 - accuracy: 0.5584 - val_loss: 4.0793 - val_accuracy: 0.0282\n",
      "Epoch 97/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5340 - accuracy: 0.5614 - val_loss: 4.0838 - val_accuracy: 0.0273\n",
      "Epoch 98/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.5220 - accuracy: 0.5641 - val_loss: 4.0886 - val_accuracy: 0.0272\n",
      "Epoch 99/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.5125 - accuracy: 0.5656 - val_loss: 4.0880 - val_accuracy: 0.0280\n",
      "Epoch 100/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.5074 - accuracy: 0.5676 - val_loss: 4.0954 - val_accuracy: 0.0273\n",
      "Epoch 101/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.4936 - accuracy: 0.5718 - val_loss: 4.1025 - val_accuracy: 0.0273\n",
      "Epoch 102/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4839 - accuracy: 0.5734 - val_loss: 4.1062 - val_accuracy: 0.0278\n",
      "Epoch 103/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4761 - accuracy: 0.5745 - val_loss: 4.1172 - val_accuracy: 0.0281\n",
      "Epoch 104/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4686 - accuracy: 0.5762 - val_loss: 4.1168 - val_accuracy: 0.0276\n",
      "Epoch 105/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4553 - accuracy: 0.5800 - val_loss: 4.1088 - val_accuracy: 0.0270\n",
      "Epoch 106/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4484 - accuracy: 0.5809 - val_loss: 4.1234 - val_accuracy: 0.0271\n",
      "Epoch 107/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4444 - accuracy: 0.5820 - val_loss: 4.1226 - val_accuracy: 0.0280\n",
      "Epoch 108/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4333 - accuracy: 0.5854 - val_loss: 4.1264 - val_accuracy: 0.0270\n",
      "Epoch 109/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4195 - accuracy: 0.5882 - val_loss: 4.1249 - val_accuracy: 0.0276\n",
      "Epoch 110/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.4136 - accuracy: 0.5912 - val_loss: 4.1443 - val_accuracy: 0.0275\n",
      "Epoch 111/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 1.4043 - accuracy: 0.5928 - val_loss: 4.1417 - val_accuracy: 0.0274\n",
      "Epoch 112/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.4008 - accuracy: 0.5944 - val_loss: 4.1411 - val_accuracy: 0.0267\n",
      "Epoch 113/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.3880 - accuracy: 0.5975 - val_loss: 4.1514 - val_accuracy: 0.0276\n",
      "Epoch 114/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.3840 - accuracy: 0.5979 - val_loss: 4.1576 - val_accuracy: 0.0282\n",
      "Epoch 115/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.3740 - accuracy: 0.6017 - val_loss: 4.1630 - val_accuracy: 0.0281\n",
      "Epoch 116/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.3655 - accuracy: 0.6032 - val_loss: 4.1536 - val_accuracy: 0.0278\n",
      "Epoch 117/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.3591 - accuracy: 0.6047 - val_loss: 4.1635 - val_accuracy: 0.0278\n",
      "Epoch 118/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.3478 - accuracy: 0.6074 - val_loss: 4.1773 - val_accuracy: 0.0274\n",
      "Epoch 119/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.3439 - accuracy: 0.6084 - val_loss: 4.1785 - val_accuracy: 0.0278\n",
      "Epoch 120/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.3358 - accuracy: 0.6092 - val_loss: 4.1785 - val_accuracy: 0.0287\n",
      "Epoch 121/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.3269 - accuracy: 0.6132 - val_loss: 4.1842 - val_accuracy: 0.0276\n",
      "Epoch 122/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.3227 - accuracy: 0.6138 - val_loss: 4.1863 - val_accuracy: 0.0285\n",
      "Epoch 123/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.3160 - accuracy: 0.6152 - val_loss: 4.1884 - val_accuracy: 0.0284\n",
      "Epoch 124/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.3029 - accuracy: 0.6197 - val_loss: 4.1934 - val_accuracy: 0.0281\n",
      "Epoch 125/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2990 - accuracy: 0.6195 - val_loss: 4.1999 - val_accuracy: 0.0279\n",
      "Epoch 126/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.2912 - accuracy: 0.6223 - val_loss: 4.1955 - val_accuracy: 0.0277\n",
      "Epoch 127/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.2879 - accuracy: 0.6223 - val_loss: 4.2034 - val_accuracy: 0.0286\n",
      "Epoch 128/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2774 - accuracy: 0.6259 - val_loss: 4.2097 - val_accuracy: 0.0286\n",
      "Epoch 129/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2714 - accuracy: 0.6267 - val_loss: 4.2155 - val_accuracy: 0.0274\n",
      "Epoch 130/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.2684 - accuracy: 0.6274 - val_loss: 4.2089 - val_accuracy: 0.0276\n",
      "Epoch 131/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2548 - accuracy: 0.6315 - val_loss: 4.2274 - val_accuracy: 0.0281\n",
      "Epoch 132/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.2533 - accuracy: 0.6317 - val_loss: 4.2287 - val_accuracy: 0.0279\n",
      "Epoch 133/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2476 - accuracy: 0.6336 - val_loss: 4.2255 - val_accuracy: 0.0268\n",
      "Epoch 134/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2420 - accuracy: 0.6339 - val_loss: 4.2329 - val_accuracy: 0.0280\n",
      "Epoch 135/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2296 - accuracy: 0.6381 - val_loss: 4.2360 - val_accuracy: 0.0279\n",
      "Epoch 136/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2291 - accuracy: 0.6377 - val_loss: 4.2414 - val_accuracy: 0.0289\n",
      "Epoch 137/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2193 - accuracy: 0.6415 - val_loss: 4.2541 - val_accuracy: 0.0272\n",
      "Epoch 138/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.2181 - accuracy: 0.6407 - val_loss: 4.2532 - val_accuracy: 0.0279\n",
      "Epoch 139/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2076 - accuracy: 0.6431 - val_loss: 4.2526 - val_accuracy: 0.0280\n",
      "Epoch 140/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.2074 - accuracy: 0.6433 - val_loss: 4.2575 - val_accuracy: 0.0282\n",
      "Epoch 141/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.1978 - accuracy: 0.6462 - val_loss: 4.2619 - val_accuracy: 0.0277\n",
      "Epoch 142/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.1935 - accuracy: 0.6463 - val_loss: 4.2715 - val_accuracy: 0.0277\n",
      "Epoch 143/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.1846 - accuracy: 0.6506 - val_loss: 4.2709 - val_accuracy: 0.0277\n",
      "Epoch 144/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.1820 - accuracy: 0.6499 - val_loss: 4.2734 - val_accuracy: 0.0278\n",
      "Epoch 145/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.1723 - accuracy: 0.6526 - val_loss: 4.2717 - val_accuracy: 0.0281\n",
      "Epoch 146/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.1672 - accuracy: 0.6549 - val_loss: 4.2738 - val_accuracy: 0.0269\n",
      "Epoch 147/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.1645 - accuracy: 0.6541 - val_loss: 4.2814 - val_accuracy: 0.0286\n",
      "Epoch 148/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.1594 - accuracy: 0.6553 - val_loss: 4.2848 - val_accuracy: 0.0281\n",
      "Epoch 149/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.1512 - accuracy: 0.6583 - val_loss: 4.2900 - val_accuracy: 0.0280\n",
      "Epoch 150/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.1503 - accuracy: 0.6584 - val_loss: 4.3014 - val_accuracy: 0.0270\n",
      "Epoch 151/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.1416 - accuracy: 0.6606 - val_loss: 4.3136 - val_accuracy: 0.0273\n",
      "Epoch 152/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.1367 - accuracy: 0.6621 - val_loss: 4.3042 - val_accuracy: 0.0274\n",
      "Epoch 153/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.1311 - accuracy: 0.6633 - val_loss: 4.3087 - val_accuracy: 0.0279\n",
      "Epoch 154/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.1249 - accuracy: 0.6653 - val_loss: 4.3110 - val_accuracy: 0.0274\n",
      "Epoch 155/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.1219 - accuracy: 0.6658 - val_loss: 4.3048 - val_accuracy: 0.0270\n",
      "Epoch 156/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.1145 - accuracy: 0.6671 - val_loss: 4.3117 - val_accuracy: 0.0277\n",
      "Epoch 157/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.1149 - accuracy: 0.6684 - val_loss: 4.3198 - val_accuracy: 0.0287\n",
      "Epoch 158/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.1076 - accuracy: 0.6696 - val_loss: 4.3163 - val_accuracy: 0.0282\n",
      "Epoch 159/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.0993 - accuracy: 0.6719 - val_loss: 4.3220 - val_accuracy: 0.0272\n",
      "Epoch 160/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0957 - accuracy: 0.6723 - val_loss: 4.3270 - val_accuracy: 0.0273\n",
      "Epoch 161/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0925 - accuracy: 0.6735 - val_loss: 4.3347 - val_accuracy: 0.0275\n",
      "Epoch 162/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.0860 - accuracy: 0.6750 - val_loss: 4.3359 - val_accuracy: 0.0274\n",
      "Epoch 163/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.0807 - accuracy: 0.6766 - val_loss: 4.3383 - val_accuracy: 0.0275\n",
      "Epoch 164/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0794 - accuracy: 0.6765 - val_loss: 4.3402 - val_accuracy: 0.0284\n",
      "Epoch 165/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0705 - accuracy: 0.6796 - val_loss: 4.3420 - val_accuracy: 0.0280\n",
      "Epoch 166/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0703 - accuracy: 0.6791 - val_loss: 4.3426 - val_accuracy: 0.0268\n",
      "Epoch 167/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.0632 - accuracy: 0.6814 - val_loss: 4.3511 - val_accuracy: 0.0278\n",
      "Epoch 168/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0562 - accuracy: 0.6830 - val_loss: 4.3499 - val_accuracy: 0.0279\n",
      "Epoch 169/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0580 - accuracy: 0.6830 - val_loss: 4.3523 - val_accuracy: 0.0274\n",
      "Epoch 170/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0495 - accuracy: 0.6847 - val_loss: 4.3599 - val_accuracy: 0.0274\n",
      "Epoch 171/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0482 - accuracy: 0.6859 - val_loss: 4.3718 - val_accuracy: 0.0274\n",
      "Epoch 172/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0417 - accuracy: 0.6862 - val_loss: 4.3598 - val_accuracy: 0.0270\n",
      "Epoch 173/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0382 - accuracy: 0.6881 - val_loss: 4.3668 - val_accuracy: 0.0275\n",
      "Epoch 174/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.0313 - accuracy: 0.6898 - val_loss: 4.3702 - val_accuracy: 0.0283\n",
      "Epoch 175/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0311 - accuracy: 0.6895 - val_loss: 4.3772 - val_accuracy: 0.0275\n",
      "Epoch 176/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.0268 - accuracy: 0.6914 - val_loss: 4.3821 - val_accuracy: 0.0292\n",
      "Epoch 177/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0188 - accuracy: 0.6935 - val_loss: 4.3823 - val_accuracy: 0.0278\n",
      "Epoch 178/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0121 - accuracy: 0.6952 - val_loss: 4.3870 - val_accuracy: 0.0278\n",
      "Epoch 179/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0146 - accuracy: 0.6939 - val_loss: 4.3961 - val_accuracy: 0.0273\n",
      "Epoch 180/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 1.0075 - accuracy: 0.6961 - val_loss: 4.3772 - val_accuracy: 0.0268\n",
      "Epoch 181/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0077 - accuracy: 0.6960 - val_loss: 4.3909 - val_accuracy: 0.0280\n",
      "Epoch 182/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 1.0023 - accuracy: 0.6976 - val_loss: 4.3877 - val_accuracy: 0.0288\n",
      "Epoch 183/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.9978 - accuracy: 0.6992 - val_loss: 4.4089 - val_accuracy: 0.0279\n",
      "Epoch 184/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.9970 - accuracy: 0.6987 - val_loss: 4.3981 - val_accuracy: 0.0276\n",
      "Epoch 185/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.9948 - accuracy: 0.6996 - val_loss: 4.3996 - val_accuracy: 0.0282\n",
      "Epoch 186/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9885 - accuracy: 0.7010 - val_loss: 4.4137 - val_accuracy: 0.0275\n",
      "Epoch 187/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.9835 - accuracy: 0.7023 - val_loss: 4.4084 - val_accuracy: 0.0269\n",
      "Epoch 188/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9821 - accuracy: 0.7032 - val_loss: 4.4132 - val_accuracy: 0.0277\n",
      "Epoch 189/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.9738 - accuracy: 0.7059 - val_loss: 4.4033 - val_accuracy: 0.0278\n",
      "Epoch 190/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9717 - accuracy: 0.7058 - val_loss: 4.4178 - val_accuracy: 0.0276\n",
      "Epoch 191/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9704 - accuracy: 0.7066 - val_loss: 4.4220 - val_accuracy: 0.0270\n",
      "Epoch 192/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.9681 - accuracy: 0.7067 - val_loss: 4.4191 - val_accuracy: 0.0270\n",
      "Epoch 193/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.9565 - accuracy: 0.7094 - val_loss: 4.4192 - val_accuracy: 0.0273\n",
      "Epoch 194/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9594 - accuracy: 0.7094 - val_loss: 4.4270 - val_accuracy: 0.0273\n",
      "Epoch 195/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9527 - accuracy: 0.7104 - val_loss: 4.4283 - val_accuracy: 0.0279\n",
      "Epoch 196/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.9538 - accuracy: 0.7106 - val_loss: 4.4338 - val_accuracy: 0.0282\n",
      "Epoch 197/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9477 - accuracy: 0.7124 - val_loss: 4.4334 - val_accuracy: 0.0281\n",
      "Epoch 198/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.9474 - accuracy: 0.7117 - val_loss: 4.4400 - val_accuracy: 0.0269\n",
      "Epoch 199/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9404 - accuracy: 0.7139 - val_loss: 4.4339 - val_accuracy: 0.0281\n",
      "Epoch 200/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.9397 - accuracy: 0.7146 - val_loss: 4.4545 - val_accuracy: 0.0277\n",
      "Epoch 201/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9306 - accuracy: 0.7170 - val_loss: 4.4558 - val_accuracy: 0.0276\n",
      "Epoch 202/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9310 - accuracy: 0.7177 - val_loss: 4.4452 - val_accuracy: 0.0282\n",
      "Epoch 203/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.9298 - accuracy: 0.7172 - val_loss: 4.4551 - val_accuracy: 0.0281\n",
      "Epoch 204/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9222 - accuracy: 0.7188 - val_loss: 4.4554 - val_accuracy: 0.0282\n",
      "Epoch 205/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.9201 - accuracy: 0.7202 - val_loss: 4.4645 - val_accuracy: 0.0285\n",
      "Epoch 206/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9188 - accuracy: 0.7203 - val_loss: 4.4591 - val_accuracy: 0.0285\n",
      "Epoch 207/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.9114 - accuracy: 0.7221 - val_loss: 4.4731 - val_accuracy: 0.0288\n",
      "Epoch 208/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.9149 - accuracy: 0.7204 - val_loss: 4.4599 - val_accuracy: 0.0284\n",
      "Epoch 209/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9069 - accuracy: 0.7229 - val_loss: 4.4756 - val_accuracy: 0.0288\n",
      "Epoch 210/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.9056 - accuracy: 0.7247 - val_loss: 4.4744 - val_accuracy: 0.0274\n",
      "Epoch 211/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.9025 - accuracy: 0.7258 - val_loss: 4.4853 - val_accuracy: 0.0278\n",
      "Epoch 212/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.9012 - accuracy: 0.7244 - val_loss: 4.4880 - val_accuracy: 0.0289\n",
      "Epoch 213/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.8949 - accuracy: 0.7275 - val_loss: 4.4909 - val_accuracy: 0.0286\n",
      "Epoch 214/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8926 - accuracy: 0.7272 - val_loss: 4.4923 - val_accuracy: 0.0284\n",
      "Epoch 215/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8877 - accuracy: 0.7296 - val_loss: 4.4898 - val_accuracy: 0.0283\n",
      "Epoch 216/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8870 - accuracy: 0.7298 - val_loss: 4.4795 - val_accuracy: 0.0279\n",
      "Epoch 217/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8855 - accuracy: 0.7299 - val_loss: 4.4899 - val_accuracy: 0.0291\n",
      "Epoch 218/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8832 - accuracy: 0.7303 - val_loss: 4.4947 - val_accuracy: 0.0279\n",
      "Epoch 219/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8744 - accuracy: 0.7321 - val_loss: 4.5080 - val_accuracy: 0.0277\n",
      "Epoch 220/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.8734 - accuracy: 0.7331 - val_loss: 4.5084 - val_accuracy: 0.0284\n",
      "Epoch 221/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8761 - accuracy: 0.7319 - val_loss: 4.4920 - val_accuracy: 0.0287\n",
      "Epoch 222/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8671 - accuracy: 0.7348 - val_loss: 4.5031 - val_accuracy: 0.0290\n",
      "Epoch 223/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8675 - accuracy: 0.7343 - val_loss: 4.5060 - val_accuracy: 0.0280\n",
      "Epoch 224/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8686 - accuracy: 0.7342 - val_loss: 4.5007 - val_accuracy: 0.0295\n",
      "Epoch 225/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8606 - accuracy: 0.7355 - val_loss: 4.5110 - val_accuracy: 0.0288\n",
      "Epoch 226/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8635 - accuracy: 0.7355 - val_loss: 4.5064 - val_accuracy: 0.0285\n",
      "Epoch 227/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.8588 - accuracy: 0.7370 - val_loss: 4.5247 - val_accuracy: 0.0286\n",
      "Epoch 228/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8560 - accuracy: 0.7375 - val_loss: 4.5283 - val_accuracy: 0.0281\n",
      "Epoch 229/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8531 - accuracy: 0.7387 - val_loss: 4.5277 - val_accuracy: 0.0279\n",
      "Epoch 230/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8466 - accuracy: 0.7403 - val_loss: 4.5263 - val_accuracy: 0.0282\n",
      "Epoch 231/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8441 - accuracy: 0.7418 - val_loss: 4.5277 - val_accuracy: 0.0290\n",
      "Epoch 232/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8446 - accuracy: 0.7419 - val_loss: 4.5385 - val_accuracy: 0.0291\n",
      "Epoch 233/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8384 - accuracy: 0.7427 - val_loss: 4.5400 - val_accuracy: 0.0282\n",
      "Epoch 234/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8389 - accuracy: 0.7428 - val_loss: 4.5272 - val_accuracy: 0.0271\n",
      "Epoch 235/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8379 - accuracy: 0.7429 - val_loss: 4.5364 - val_accuracy: 0.0286\n",
      "Epoch 236/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8320 - accuracy: 0.7438 - val_loss: 4.5380 - val_accuracy: 0.0281\n",
      "Epoch 237/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8300 - accuracy: 0.7453 - val_loss: 4.5437 - val_accuracy: 0.0281\n",
      "Epoch 238/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8335 - accuracy: 0.7444 - val_loss: 4.5516 - val_accuracy: 0.0279\n",
      "Epoch 239/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8243 - accuracy: 0.7466 - val_loss: 4.5540 - val_accuracy: 0.0276\n",
      "Epoch 240/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8236 - accuracy: 0.7472 - val_loss: 4.5347 - val_accuracy: 0.0283\n",
      "Epoch 241/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.8236 - accuracy: 0.7471 - val_loss: 4.5396 - val_accuracy: 0.0285\n",
      "Epoch 242/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8174 - accuracy: 0.7487 - val_loss: 4.5482 - val_accuracy: 0.0281\n",
      "Epoch 243/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8182 - accuracy: 0.7478 - val_loss: 4.5533 - val_accuracy: 0.0280\n",
      "Epoch 244/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.8143 - accuracy: 0.7497 - val_loss: 4.5627 - val_accuracy: 0.0278\n",
      "Epoch 245/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.8126 - accuracy: 0.7493 - val_loss: 4.5530 - val_accuracy: 0.0282\n",
      "Epoch 246/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8110 - accuracy: 0.7503 - val_loss: 4.5447 - val_accuracy: 0.0271\n",
      "Epoch 247/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8040 - accuracy: 0.7519 - val_loss: 4.5654 - val_accuracy: 0.0276\n",
      "Epoch 248/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.8032 - accuracy: 0.7527 - val_loss: 4.5572 - val_accuracy: 0.0290\n",
      "Epoch 249/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8027 - accuracy: 0.7520 - val_loss: 4.5704 - val_accuracy: 0.0290\n",
      "Epoch 250/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.8064 - accuracy: 0.7499 - val_loss: 4.5563 - val_accuracy: 0.0285\n",
      "Epoch 251/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.8005 - accuracy: 0.7533 - val_loss: 4.5729 - val_accuracy: 0.0285\n",
      "Epoch 252/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7965 - accuracy: 0.7537 - val_loss: 4.5788 - val_accuracy: 0.0278\n",
      "Epoch 253/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.7948 - accuracy: 0.7548 - val_loss: 4.5742 - val_accuracy: 0.0281\n",
      "Epoch 254/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7902 - accuracy: 0.7554 - val_loss: 4.5883 - val_accuracy: 0.0276\n",
      "Epoch 255/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7925 - accuracy: 0.7563 - val_loss: 4.5796 - val_accuracy: 0.0281\n",
      "Epoch 256/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7866 - accuracy: 0.7580 - val_loss: 4.5928 - val_accuracy: 0.0291\n",
      "Epoch 257/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7888 - accuracy: 0.7566 - val_loss: 4.5814 - val_accuracy: 0.0283\n",
      "Epoch 258/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7845 - accuracy: 0.7582 - val_loss: 4.5752 - val_accuracy: 0.0282\n",
      "Epoch 259/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7813 - accuracy: 0.7584 - val_loss: 4.5940 - val_accuracy: 0.0284\n",
      "Epoch 260/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7800 - accuracy: 0.7587 - val_loss: 4.5970 - val_accuracy: 0.0273\n",
      "Epoch 261/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7762 - accuracy: 0.7599 - val_loss: 4.5960 - val_accuracy: 0.0285\n",
      "Epoch 262/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7730 - accuracy: 0.7606 - val_loss: 4.6006 - val_accuracy: 0.0293\n",
      "Epoch 263/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7765 - accuracy: 0.7598 - val_loss: 4.5996 - val_accuracy: 0.0292\n",
      "Epoch 264/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7737 - accuracy: 0.7611 - val_loss: 4.5902 - val_accuracy: 0.0278\n",
      "Epoch 265/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7691 - accuracy: 0.7625 - val_loss: 4.5988 - val_accuracy: 0.0281\n",
      "Epoch 266/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7663 - accuracy: 0.7629 - val_loss: 4.5991 - val_accuracy: 0.0286\n",
      "Epoch 267/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7678 - accuracy: 0.7620 - val_loss: 4.6047 - val_accuracy: 0.0291\n",
      "Epoch 268/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7617 - accuracy: 0.7645 - val_loss: 4.6168 - val_accuracy: 0.0277\n",
      "Epoch 269/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7630 - accuracy: 0.7632 - val_loss: 4.5935 - val_accuracy: 0.0281\n",
      "Epoch 270/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7587 - accuracy: 0.7653 - val_loss: 4.6030 - val_accuracy: 0.0284\n",
      "Epoch 271/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7543 - accuracy: 0.7659 - val_loss: 4.6080 - val_accuracy: 0.0282\n",
      "Epoch 272/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7610 - accuracy: 0.7647 - val_loss: 4.6066 - val_accuracy: 0.0286\n",
      "Epoch 273/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7497 - accuracy: 0.7683 - val_loss: 4.6221 - val_accuracy: 0.0287\n",
      "Epoch 274/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7526 - accuracy: 0.7666 - val_loss: 4.6162 - val_accuracy: 0.0287\n",
      "Epoch 275/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7497 - accuracy: 0.7677 - val_loss: 4.6378 - val_accuracy: 0.0284\n",
      "Epoch 276/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7467 - accuracy: 0.7682 - val_loss: 4.6168 - val_accuracy: 0.0289\n",
      "Epoch 277/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.7441 - accuracy: 0.7685 - val_loss: 4.6307 - val_accuracy: 0.0287\n",
      "Epoch 278/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.7382 - accuracy: 0.7715 - val_loss: 4.6224 - val_accuracy: 0.0280\n",
      "Epoch 279/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7398 - accuracy: 0.7698 - val_loss: 4.6333 - val_accuracy: 0.0275\n",
      "Epoch 280/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7405 - accuracy: 0.7703 - val_loss: 4.6280 - val_accuracy: 0.0281\n",
      "Epoch 281/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7355 - accuracy: 0.7719 - val_loss: 4.6362 - val_accuracy: 0.0288\n",
      "Epoch 282/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7354 - accuracy: 0.7717 - val_loss: 4.6359 - val_accuracy: 0.0279\n",
      "Epoch 283/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7364 - accuracy: 0.7717 - val_loss: 4.6470 - val_accuracy: 0.0288\n",
      "Epoch 284/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7354 - accuracy: 0.7714 - val_loss: 4.6374 - val_accuracy: 0.0277\n",
      "Epoch 285/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7335 - accuracy: 0.7727 - val_loss: 4.6354 - val_accuracy: 0.0272\n",
      "Epoch 286/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7305 - accuracy: 0.7733 - val_loss: 4.6304 - val_accuracy: 0.0282\n",
      "Epoch 287/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7248 - accuracy: 0.7744 - val_loss: 4.6425 - val_accuracy: 0.0281\n",
      "Epoch 288/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7238 - accuracy: 0.7750 - val_loss: 4.6506 - val_accuracy: 0.0283\n",
      "Epoch 289/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7249 - accuracy: 0.7753 - val_loss: 4.6476 - val_accuracy: 0.0282\n",
      "Epoch 290/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7233 - accuracy: 0.7744 - val_loss: 4.6502 - val_accuracy: 0.0276\n",
      "Epoch 291/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7222 - accuracy: 0.7760 - val_loss: 4.6354 - val_accuracy: 0.0282\n",
      "Epoch 292/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7235 - accuracy: 0.7752 - val_loss: 4.6516 - val_accuracy: 0.0286\n",
      "Epoch 293/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.7172 - accuracy: 0.7755 - val_loss: 4.6448 - val_accuracy: 0.0293\n",
      "Epoch 294/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7152 - accuracy: 0.7777 - val_loss: 4.6533 - val_accuracy: 0.0279\n",
      "Epoch 295/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7135 - accuracy: 0.7783 - val_loss: 4.6629 - val_accuracy: 0.0284\n",
      "Epoch 296/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.7114 - accuracy: 0.7784 - val_loss: 4.6679 - val_accuracy: 0.0273\n",
      "Epoch 297/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.7142 - accuracy: 0.7778 - val_loss: 4.6857 - val_accuracy: 0.0283\n",
      "Epoch 298/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7035 - accuracy: 0.7807 - val_loss: 4.6692 - val_accuracy: 0.0288\n",
      "Epoch 299/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7071 - accuracy: 0.7787 - val_loss: 4.6773 - val_accuracy: 0.0287\n",
      "Epoch 300/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7082 - accuracy: 0.7798 - val_loss: 4.6623 - val_accuracy: 0.0291\n",
      "Epoch 301/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.7050 - accuracy: 0.7804 - val_loss: 4.6645 - val_accuracy: 0.0278\n",
      "Epoch 302/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7040 - accuracy: 0.7811 - val_loss: 4.6781 - val_accuracy: 0.0284\n",
      "Epoch 303/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.7035 - accuracy: 0.7811 - val_loss: 4.6857 - val_accuracy: 0.0281\n",
      "Epoch 304/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6989 - accuracy: 0.7826 - val_loss: 4.6758 - val_accuracy: 0.0293\n",
      "Epoch 305/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6983 - accuracy: 0.7822 - val_loss: 4.6768 - val_accuracy: 0.0286\n",
      "Epoch 306/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6981 - accuracy: 0.7815 - val_loss: 4.6881 - val_accuracy: 0.0278\n",
      "Epoch 307/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6931 - accuracy: 0.7840 - val_loss: 4.6734 - val_accuracy: 0.0284\n",
      "Epoch 308/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6951 - accuracy: 0.7834 - val_loss: 4.6887 - val_accuracy: 0.0282\n",
      "Epoch 309/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6930 - accuracy: 0.7840 - val_loss: 4.6947 - val_accuracy: 0.0283\n",
      "Epoch 310/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6955 - accuracy: 0.7829 - val_loss: 4.6883 - val_accuracy: 0.0283\n",
      "Epoch 311/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6880 - accuracy: 0.7852 - val_loss: 4.6883 - val_accuracy: 0.0286\n",
      "Epoch 312/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6899 - accuracy: 0.7836 - val_loss: 4.6861 - val_accuracy: 0.0284\n",
      "Epoch 313/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6850 - accuracy: 0.7853 - val_loss: 4.7045 - val_accuracy: 0.0275\n",
      "Epoch 314/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6879 - accuracy: 0.7846 - val_loss: 4.6973 - val_accuracy: 0.0278\n",
      "Epoch 315/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6835 - accuracy: 0.7870 - val_loss: 4.7009 - val_accuracy: 0.0286\n",
      "Epoch 316/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6849 - accuracy: 0.7859 - val_loss: 4.6998 - val_accuracy: 0.0283\n",
      "Epoch 317/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6839 - accuracy: 0.7863 - val_loss: 4.6885 - val_accuracy: 0.0274\n",
      "Epoch 318/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6760 - accuracy: 0.7886 - val_loss: 4.7206 - val_accuracy: 0.0281\n",
      "Epoch 319/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6798 - accuracy: 0.7886 - val_loss: 4.6878 - val_accuracy: 0.0285\n",
      "Epoch 320/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6743 - accuracy: 0.7903 - val_loss: 4.7056 - val_accuracy: 0.0282\n",
      "Epoch 321/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6734 - accuracy: 0.7888 - val_loss: 4.7173 - val_accuracy: 0.0285\n",
      "Epoch 322/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6764 - accuracy: 0.7881 - val_loss: 4.6992 - val_accuracy: 0.0283\n",
      "Epoch 323/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6699 - accuracy: 0.7908 - val_loss: 4.7192 - val_accuracy: 0.0290\n",
      "Epoch 324/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6686 - accuracy: 0.7917 - val_loss: 4.7208 - val_accuracy: 0.0283\n",
      "Epoch 325/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.6677 - accuracy: 0.7910 - val_loss: 4.7169 - val_accuracy: 0.0280\n",
      "Epoch 326/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6710 - accuracy: 0.7902 - val_loss: 4.6856 - val_accuracy: 0.0283\n",
      "Epoch 327/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6655 - accuracy: 0.7918 - val_loss: 4.7157 - val_accuracy: 0.0285\n",
      "Epoch 328/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6674 - accuracy: 0.7915 - val_loss: 4.7116 - val_accuracy: 0.0285\n",
      "Epoch 329/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6616 - accuracy: 0.7933 - val_loss: 4.7192 - val_accuracy: 0.0285\n",
      "Epoch 330/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6659 - accuracy: 0.7923 - val_loss: 4.7227 - val_accuracy: 0.0286\n",
      "Epoch 331/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6601 - accuracy: 0.7935 - val_loss: 4.7250 - val_accuracy: 0.0281\n",
      "Epoch 332/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6561 - accuracy: 0.7947 - val_loss: 4.7186 - val_accuracy: 0.0281\n",
      "Epoch 333/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6613 - accuracy: 0.7931 - val_loss: 4.7239 - val_accuracy: 0.0277\n",
      "Epoch 334/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.6567 - accuracy: 0.7936 - val_loss: 4.7217 - val_accuracy: 0.0285\n",
      "Epoch 335/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6566 - accuracy: 0.7948 - val_loss: 4.7286 - val_accuracy: 0.0290\n",
      "Epoch 336/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6514 - accuracy: 0.7959 - val_loss: 4.7415 - val_accuracy: 0.0276\n",
      "Epoch 337/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6497 - accuracy: 0.7965 - val_loss: 4.7220 - val_accuracy: 0.0276\n",
      "Epoch 338/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6530 - accuracy: 0.7956 - val_loss: 4.7384 - val_accuracy: 0.0284\n",
      "Epoch 339/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6520 - accuracy: 0.7953 - val_loss: 4.7324 - val_accuracy: 0.0277\n",
      "Epoch 340/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6495 - accuracy: 0.7970 - val_loss: 4.7281 - val_accuracy: 0.0282\n",
      "Epoch 341/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.6467 - accuracy: 0.7973 - val_loss: 4.7284 - val_accuracy: 0.0275\n",
      "Epoch 342/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6451 - accuracy: 0.7973 - val_loss: 4.7303 - val_accuracy: 0.0288\n",
      "Epoch 343/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6491 - accuracy: 0.7961 - val_loss: 4.7265 - val_accuracy: 0.0283\n",
      "Epoch 344/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6423 - accuracy: 0.7982 - val_loss: 4.7495 - val_accuracy: 0.0291\n",
      "Epoch 345/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6405 - accuracy: 0.7994 - val_loss: 4.7470 - val_accuracy: 0.0281\n",
      "Epoch 346/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6432 - accuracy: 0.7983 - val_loss: 4.7485 - val_accuracy: 0.0288\n",
      "Epoch 347/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6424 - accuracy: 0.7985 - val_loss: 4.7438 - val_accuracy: 0.0277\n",
      "Epoch 348/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6419 - accuracy: 0.7988 - val_loss: 4.7494 - val_accuracy: 0.0282\n",
      "Epoch 349/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6405 - accuracy: 0.7985 - val_loss: 4.7437 - val_accuracy: 0.0265\n",
      "Epoch 350/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6341 - accuracy: 0.8007 - val_loss: 4.7494 - val_accuracy: 0.0282\n",
      "Epoch 351/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6347 - accuracy: 0.7999 - val_loss: 4.7659 - val_accuracy: 0.0291\n",
      "Epoch 352/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.6321 - accuracy: 0.8025 - val_loss: 4.7581 - val_accuracy: 0.0282\n",
      "Epoch 353/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6357 - accuracy: 0.8008 - val_loss: 4.7616 - val_accuracy: 0.0277\n",
      "Epoch 354/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6355 - accuracy: 0.8008 - val_loss: 4.7524 - val_accuracy: 0.0283\n",
      "Epoch 355/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6301 - accuracy: 0.8021 - val_loss: 4.7559 - val_accuracy: 0.0271\n",
      "Epoch 356/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6303 - accuracy: 0.8019 - val_loss: 4.7618 - val_accuracy: 0.0272\n",
      "Epoch 357/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6276 - accuracy: 0.8029 - val_loss: 4.7580 - val_accuracy: 0.0267\n",
      "Epoch 358/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6303 - accuracy: 0.8022 - val_loss: 4.7651 - val_accuracy: 0.0282\n",
      "Epoch 359/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6255 - accuracy: 0.8028 - val_loss: 4.7563 - val_accuracy: 0.0274\n",
      "Epoch 360/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.6199 - accuracy: 0.8050 - val_loss: 4.7674 - val_accuracy: 0.0284\n",
      "Epoch 361/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6282 - accuracy: 0.8022 - val_loss: 4.7574 - val_accuracy: 0.0297\n",
      "Epoch 362/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6226 - accuracy: 0.8045 - val_loss: 4.7666 - val_accuracy: 0.0282\n",
      "Epoch 363/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6239 - accuracy: 0.8042 - val_loss: 4.7740 - val_accuracy: 0.0293\n",
      "Epoch 364/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.6170 - accuracy: 0.8056 - val_loss: 4.7715 - val_accuracy: 0.0272\n",
      "Epoch 365/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6194 - accuracy: 0.8061 - val_loss: 4.7586 - val_accuracy: 0.0283\n",
      "Epoch 366/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6226 - accuracy: 0.8040 - val_loss: 4.7608 - val_accuracy: 0.0284\n",
      "Epoch 367/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6205 - accuracy: 0.8048 - val_loss: 4.7828 - val_accuracy: 0.0279\n",
      "Epoch 368/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6139 - accuracy: 0.8071 - val_loss: 4.7899 - val_accuracy: 0.0281\n",
      "Epoch 369/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.6157 - accuracy: 0.8065 - val_loss: 4.7912 - val_accuracy: 0.0278\n",
      "Epoch 370/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.6144 - accuracy: 0.8061 - val_loss: 4.7795 - val_accuracy: 0.0291\n",
      "Epoch 371/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6089 - accuracy: 0.8079 - val_loss: 4.7808 - val_accuracy: 0.0283\n",
      "Epoch 372/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6121 - accuracy: 0.8068 - val_loss: 4.7836 - val_accuracy: 0.0283\n",
      "Epoch 373/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6162 - accuracy: 0.8057 - val_loss: 4.7764 - val_accuracy: 0.0281\n",
      "Epoch 374/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.6074 - accuracy: 0.8089 - val_loss: 4.7970 - val_accuracy: 0.0290\n",
      "Epoch 375/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6077 - accuracy: 0.8084 - val_loss: 4.7788 - val_accuracy: 0.0279\n",
      "Epoch 376/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6077 - accuracy: 0.8083 - val_loss: 4.7754 - val_accuracy: 0.0279\n",
      "Epoch 377/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6087 - accuracy: 0.8079 - val_loss: 4.7944 - val_accuracy: 0.0279\n",
      "Epoch 378/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6092 - accuracy: 0.8076 - val_loss: 4.7936 - val_accuracy: 0.0283\n",
      "Epoch 379/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.6044 - accuracy: 0.8092 - val_loss: 4.7850 - val_accuracy: 0.0283\n",
      "Epoch 380/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.6017 - accuracy: 0.8104 - val_loss: 4.7826 - val_accuracy: 0.0269\n",
      "Epoch 381/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6004 - accuracy: 0.8101 - val_loss: 4.7992 - val_accuracy: 0.0286\n",
      "Epoch 382/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6001 - accuracy: 0.8106 - val_loss: 4.8065 - val_accuracy: 0.0277\n",
      "Epoch 383/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6037 - accuracy: 0.8092 - val_loss: 4.7895 - val_accuracy: 0.0277\n",
      "Epoch 384/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.6020 - accuracy: 0.8106 - val_loss: 4.7893 - val_accuracy: 0.0277\n",
      "Epoch 385/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5968 - accuracy: 0.8127 - val_loss: 4.8062 - val_accuracy: 0.0283\n",
      "Epoch 386/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5954 - accuracy: 0.8124 - val_loss: 4.8082 - val_accuracy: 0.0280\n",
      "Epoch 387/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5952 - accuracy: 0.8124 - val_loss: 4.8001 - val_accuracy: 0.0284\n",
      "Epoch 388/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5959 - accuracy: 0.8124 - val_loss: 4.8116 - val_accuracy: 0.0273\n",
      "Epoch 389/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5967 - accuracy: 0.8117 - val_loss: 4.8070 - val_accuracy: 0.0283\n",
      "Epoch 390/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5928 - accuracy: 0.8132 - val_loss: 4.8135 - val_accuracy: 0.0281\n",
      "Epoch 391/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5953 - accuracy: 0.8123 - val_loss: 4.8156 - val_accuracy: 0.0278\n",
      "Epoch 392/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5926 - accuracy: 0.8121 - val_loss: 4.8099 - val_accuracy: 0.0274\n",
      "Epoch 393/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5897 - accuracy: 0.8146 - val_loss: 4.8060 - val_accuracy: 0.0278\n",
      "Epoch 394/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5920 - accuracy: 0.8142 - val_loss: 4.8084 - val_accuracy: 0.0283\n",
      "Epoch 395/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5892 - accuracy: 0.8130 - val_loss: 4.8089 - val_accuracy: 0.0287\n",
      "Epoch 396/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5914 - accuracy: 0.8144 - val_loss: 4.7981 - val_accuracy: 0.0272\n",
      "Epoch 397/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5876 - accuracy: 0.8149 - val_loss: 4.8158 - val_accuracy: 0.0276\n",
      "Epoch 398/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5862 - accuracy: 0.8153 - val_loss: 4.8037 - val_accuracy: 0.0280\n",
      "Epoch 399/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5860 - accuracy: 0.8151 - val_loss: 4.8052 - val_accuracy: 0.0284\n",
      "Epoch 400/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5826 - accuracy: 0.8164 - val_loss: 4.8173 - val_accuracy: 0.0279\n",
      "Epoch 401/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5832 - accuracy: 0.8157 - val_loss: 4.8315 - val_accuracy: 0.0267\n",
      "Epoch 402/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5849 - accuracy: 0.8152 - val_loss: 4.8222 - val_accuracy: 0.0281\n",
      "Epoch 403/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5835 - accuracy: 0.8152 - val_loss: 4.8278 - val_accuracy: 0.0280\n",
      "Epoch 404/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5792 - accuracy: 0.8164 - val_loss: 4.8273 - val_accuracy: 0.0280\n",
      "Epoch 405/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5778 - accuracy: 0.8177 - val_loss: 4.8232 - val_accuracy: 0.0274\n",
      "Epoch 406/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5778 - accuracy: 0.8165 - val_loss: 4.8260 - val_accuracy: 0.0274\n",
      "Epoch 407/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5780 - accuracy: 0.8170 - val_loss: 4.8200 - val_accuracy: 0.0282\n",
      "Epoch 408/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5773 - accuracy: 0.8177 - val_loss: 4.8398 - val_accuracy: 0.0279\n",
      "Epoch 409/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5775 - accuracy: 0.8173 - val_loss: 4.8164 - val_accuracy: 0.0282\n",
      "Epoch 410/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5756 - accuracy: 0.8181 - val_loss: 4.8458 - val_accuracy: 0.0272\n",
      "Epoch 411/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5738 - accuracy: 0.8182 - val_loss: 4.8224 - val_accuracy: 0.0277\n",
      "Epoch 412/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5740 - accuracy: 0.8188 - val_loss: 4.8408 - val_accuracy: 0.0276\n",
      "Epoch 413/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5746 - accuracy: 0.8176 - val_loss: 4.8280 - val_accuracy: 0.0279\n",
      "Epoch 414/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5691 - accuracy: 0.8202 - val_loss: 4.8398 - val_accuracy: 0.0286\n",
      "Epoch 415/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5707 - accuracy: 0.8191 - val_loss: 4.8457 - val_accuracy: 0.0284\n",
      "Epoch 416/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5661 - accuracy: 0.8208 - val_loss: 4.8212 - val_accuracy: 0.0279\n",
      "Epoch 417/500\n",
      "263/263 [==============================] - 66s 251ms/step - loss: 0.5713 - accuracy: 0.8196 - val_loss: 4.8385 - val_accuracy: 0.0286\n",
      "Epoch 418/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5668 - accuracy: 0.8216 - val_loss: 4.8267 - val_accuracy: 0.0282\n",
      "Epoch 419/500\n",
      "263/263 [==============================] - 66s 251ms/step - loss: 0.5677 - accuracy: 0.8201 - val_loss: 4.8418 - val_accuracy: 0.0284\n",
      "Epoch 420/500\n",
      "263/263 [==============================] - 68s 260ms/step - loss: 0.5630 - accuracy: 0.8215 - val_loss: 4.8438 - val_accuracy: 0.0283\n",
      "Epoch 421/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5670 - accuracy: 0.8207 - val_loss: 4.8374 - val_accuracy: 0.0287\n",
      "Epoch 422/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5679 - accuracy: 0.8206 - val_loss: 4.8244 - val_accuracy: 0.0286\n",
      "Epoch 423/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5642 - accuracy: 0.8222 - val_loss: 4.8358 - val_accuracy: 0.0284\n",
      "Epoch 424/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5638 - accuracy: 0.8216 - val_loss: 4.8588 - val_accuracy: 0.0282\n",
      "Epoch 425/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5599 - accuracy: 0.8228 - val_loss: 4.8459 - val_accuracy: 0.0279\n",
      "Epoch 426/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5608 - accuracy: 0.8229 - val_loss: 4.8427 - val_accuracy: 0.0272\n",
      "Epoch 427/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5594 - accuracy: 0.8235 - val_loss: 4.8609 - val_accuracy: 0.0277\n",
      "Epoch 428/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5561 - accuracy: 0.8238 - val_loss: 4.8490 - val_accuracy: 0.0275\n",
      "Epoch 429/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5548 - accuracy: 0.8237 - val_loss: 4.8491 - val_accuracy: 0.0279\n",
      "Epoch 430/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5552 - accuracy: 0.8240 - val_loss: 4.8551 - val_accuracy: 0.0280\n",
      "Epoch 431/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5580 - accuracy: 0.8240 - val_loss: 4.8487 - val_accuracy: 0.0269\n",
      "Epoch 432/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5567 - accuracy: 0.8232 - val_loss: 4.8730 - val_accuracy: 0.0279\n",
      "Epoch 433/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5546 - accuracy: 0.8245 - val_loss: 4.8470 - val_accuracy: 0.0268\n",
      "Epoch 434/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5542 - accuracy: 0.8246 - val_loss: 4.8641 - val_accuracy: 0.0281\n",
      "Epoch 435/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5534 - accuracy: 0.8256 - val_loss: 4.8638 - val_accuracy: 0.0277\n",
      "Epoch 436/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5540 - accuracy: 0.8241 - val_loss: 4.8705 - val_accuracy: 0.0271\n",
      "Epoch 437/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5496 - accuracy: 0.8255 - val_loss: 4.8811 - val_accuracy: 0.0275\n",
      "Epoch 438/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5529 - accuracy: 0.8249 - val_loss: 4.8524 - val_accuracy: 0.0278\n",
      "Epoch 439/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5485 - accuracy: 0.8265 - val_loss: 4.8764 - val_accuracy: 0.0264\n",
      "Epoch 440/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5483 - accuracy: 0.8254 - val_loss: 4.8609 - val_accuracy: 0.0269\n",
      "Epoch 441/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5482 - accuracy: 0.8260 - val_loss: 4.8657 - val_accuracy: 0.0271\n",
      "Epoch 442/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5482 - accuracy: 0.8259 - val_loss: 4.8769 - val_accuracy: 0.0278\n",
      "Epoch 443/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5461 - accuracy: 0.8270 - val_loss: 4.8650 - val_accuracy: 0.0278\n",
      "Epoch 444/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5450 - accuracy: 0.8265 - val_loss: 4.8749 - val_accuracy: 0.0278\n",
      "Epoch 445/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5461 - accuracy: 0.8264 - val_loss: 4.8636 - val_accuracy: 0.0280\n",
      "Epoch 446/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5428 - accuracy: 0.8277 - val_loss: 4.8839 - val_accuracy: 0.0282\n",
      "Epoch 447/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5457 - accuracy: 0.8269 - val_loss: 4.8825 - val_accuracy: 0.0264\n",
      "Epoch 448/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5411 - accuracy: 0.8280 - val_loss: 4.8870 - val_accuracy: 0.0268\n",
      "Epoch 449/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5403 - accuracy: 0.8289 - val_loss: 4.8691 - val_accuracy: 0.0261\n",
      "Epoch 450/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5425 - accuracy: 0.8277 - val_loss: 4.8831 - val_accuracy: 0.0270\n",
      "Epoch 451/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5390 - accuracy: 0.8300 - val_loss: 4.8777 - val_accuracy: 0.0274\n",
      "Epoch 452/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5373 - accuracy: 0.8296 - val_loss: 4.8880 - val_accuracy: 0.0280\n",
      "Epoch 453/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5409 - accuracy: 0.8282 - val_loss: 4.8967 - val_accuracy: 0.0268\n",
      "Epoch 454/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5368 - accuracy: 0.8296 - val_loss: 4.8915 - val_accuracy: 0.0274\n",
      "Epoch 455/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5399 - accuracy: 0.8292 - val_loss: 4.8871 - val_accuracy: 0.0271\n",
      "Epoch 456/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5377 - accuracy: 0.8293 - val_loss: 4.8717 - val_accuracy: 0.0275\n",
      "Epoch 457/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5363 - accuracy: 0.8297 - val_loss: 4.8873 - val_accuracy: 0.0276\n",
      "Epoch 458/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5368 - accuracy: 0.8297 - val_loss: 4.9061 - val_accuracy: 0.0274\n",
      "Epoch 459/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5317 - accuracy: 0.8308 - val_loss: 4.8940 - val_accuracy: 0.0268\n",
      "Epoch 460/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5353 - accuracy: 0.8300 - val_loss: 4.8879 - val_accuracy: 0.0270\n",
      "Epoch 461/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5349 - accuracy: 0.8301 - val_loss: 4.8737 - val_accuracy: 0.0276\n",
      "Epoch 462/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5331 - accuracy: 0.8306 - val_loss: 4.8863 - val_accuracy: 0.0272\n",
      "Epoch 463/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5302 - accuracy: 0.8323 - val_loss: 4.9089 - val_accuracy: 0.0281\n",
      "Epoch 464/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5327 - accuracy: 0.8312 - val_loss: 4.8805 - val_accuracy: 0.0278\n",
      "Epoch 465/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5312 - accuracy: 0.8308 - val_loss: 4.9057 - val_accuracy: 0.0272\n",
      "Epoch 466/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5284 - accuracy: 0.8323 - val_loss: 4.8841 - val_accuracy: 0.0269\n",
      "Epoch 467/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5317 - accuracy: 0.8316 - val_loss: 4.8964 - val_accuracy: 0.0274\n",
      "Epoch 468/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5317 - accuracy: 0.8306 - val_loss: 4.8836 - val_accuracy: 0.0281\n",
      "Epoch 469/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5300 - accuracy: 0.8319 - val_loss: 4.8972 - val_accuracy: 0.0276\n",
      "Epoch 470/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5273 - accuracy: 0.8322 - val_loss: 4.8995 - val_accuracy: 0.0283\n",
      "Epoch 471/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5262 - accuracy: 0.8333 - val_loss: 4.9048 - val_accuracy: 0.0273\n",
      "Epoch 472/500\n",
      "263/263 [==============================] - 66s 250ms/step - loss: 0.5270 - accuracy: 0.8329 - val_loss: 4.8953 - val_accuracy: 0.0274\n",
      "Epoch 473/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5257 - accuracy: 0.8325 - val_loss: 4.9040 - val_accuracy: 0.0284\n",
      "Epoch 474/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5263 - accuracy: 0.8324 - val_loss: 4.9114 - val_accuracy: 0.0265\n",
      "Epoch 475/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5266 - accuracy: 0.8328 - val_loss: 4.9095 - val_accuracy: 0.0276\n",
      "Epoch 476/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5234 - accuracy: 0.8333 - val_loss: 4.8975 - val_accuracy: 0.0270\n",
      "Epoch 477/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5235 - accuracy: 0.8336 - val_loss: 4.9026 - val_accuracy: 0.0263\n",
      "Epoch 478/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5196 - accuracy: 0.8349 - val_loss: 4.9206 - val_accuracy: 0.0268\n",
      "Epoch 479/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5214 - accuracy: 0.8342 - val_loss: 4.9059 - val_accuracy: 0.0266\n",
      "Epoch 480/500\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 0.5219 - accuracy: 0.8347 - val_loss: 4.9166 - val_accuracy: 0.0267\n",
      "Epoch 481/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5198 - accuracy: 0.8345 - val_loss: 4.9099 - val_accuracy: 0.0277\n",
      "Epoch 482/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5231 - accuracy: 0.8333 - val_loss: 4.9070 - val_accuracy: 0.0274\n",
      "Epoch 483/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5211 - accuracy: 0.8346 - val_loss: 4.9051 - val_accuracy: 0.0264\n",
      "Epoch 484/500\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.5176 - accuracy: 0.8355 - val_loss: 4.9260 - val_accuracy: 0.0272\n",
      "Epoch 485/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5188 - accuracy: 0.8355 - val_loss: 4.9297 - val_accuracy: 0.0272\n",
      "Epoch 486/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5134 - accuracy: 0.8366 - val_loss: 4.9071 - val_accuracy: 0.0276\n",
      "Epoch 487/500\n",
      "263/263 [==============================] - 68s 259ms/step - loss: 0.5170 - accuracy: 0.8349 - val_loss: 4.9093 - val_accuracy: 0.0272\n",
      "Epoch 488/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5168 - accuracy: 0.8363 - val_loss: 4.9277 - val_accuracy: 0.0272\n",
      "Epoch 489/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5107 - accuracy: 0.8375 - val_loss: 4.9250 - val_accuracy: 0.0278\n",
      "Epoch 490/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5173 - accuracy: 0.8359 - val_loss: 4.9245 - val_accuracy: 0.0274\n",
      "Epoch 491/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5148 - accuracy: 0.8360 - val_loss: 4.9428 - val_accuracy: 0.0276\n",
      "Epoch 492/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5136 - accuracy: 0.8360 - val_loss: 4.9033 - val_accuracy: 0.0271\n",
      "Epoch 493/500\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.5125 - accuracy: 0.8370 - val_loss: 4.9203 - val_accuracy: 0.0281\n",
      "Epoch 494/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5145 - accuracy: 0.8354 - val_loss: 4.9251 - val_accuracy: 0.0277\n",
      "Epoch 495/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5136 - accuracy: 0.8370 - val_loss: 4.9229 - val_accuracy: 0.0286\n",
      "Epoch 496/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5107 - accuracy: 0.8379 - val_loss: 4.9184 - val_accuracy: 0.0277\n",
      "Epoch 497/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5061 - accuracy: 0.8385 - val_loss: 4.9394 - val_accuracy: 0.0280\n",
      "Epoch 498/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5056 - accuracy: 0.8393 - val_loss: 4.9220 - val_accuracy: 0.0286\n",
      "Epoch 499/500\n",
      "263/263 [==============================] - 68s 258ms/step - loss: 0.5110 - accuracy: 0.8374 - val_loss: 4.9323 - val_accuracy: 0.0275\n",
      "Epoch 500/500\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 0.5095 - accuracy: 0.8376 - val_loss: 4.9479 - val_accuracy: 0.0281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c5aec186690>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_network.fit(newx_train,newy_train,validation_data=(newx_test,newy_test),epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d898741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T01:06:07.501048Z",
     "iopub.status.busy": "2023-04-11T01:06:07.500667Z",
     "iopub.status.idle": "2023-04-11T01:06:15.700914Z",
     "shell.execute_reply": "2023-04-11T01:06:15.699844Z"
    },
    "papermill": {
     "duration": 15.610598,
     "end_time": "2023-04-11T01:06:15.703853",
     "exception": false,
     "start_time": "2023-04-11T01:06:00.093255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "siamese_network.save_weights(\"model_landmarks.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37453.403404,
   "end_time": "2023-04-11T01:06:26.618895",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-10T14:42:13.215491",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
